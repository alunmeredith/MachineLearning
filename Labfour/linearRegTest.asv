% load the data and normalise its mean/variance
loadData

% split into training / testing sets
% set aside 20% for testing set later
ii = cvIndicies(Y,5);
Ytest = Y(ii == 1, :);
ftest = Y(ii == 1, :);
Ytrain = Y(ii ~= 1, :);
ftrain = Y(ii ~= 1, :);

% basic linear Regression
linearReg(Y,f,'train');


% consider cross val ind function
fold = cvIndices(Y, 10);

for i = 1:k

Ytr = Y(fold == i, :);
ftr = f(fold == i, :);
Yts = Y(fold ~= i, :);
fts = f(fold ~= i, :);


% Estimate regression model (w) on the training set
[w, fhtr] = linearReg(Ytr, ftr, 'train');

% Errors on training set
RMSEtrain(i) = sqrt( sum((fhtr - ftr).^2) / (N-2) );

% Errors on test set
[wtsm fhts] = linearReg(Yts, fts, w);
RMSEtest(i) = sqrt( sum((fhts - fts).^2) / (N-2) );
wCV(i) = wtsm;

end

% SSEts is the error on the training data for each fold. If we assume it is
% normally distributed via the central limit theorem we can calculate a
% confidence interval for it.